#include "Cmm.h"

/* -----------------------------------------------------------------------------
 * Partial Abort TVar primitives
 * -------------------------------------------------------------------------- */

// This must match StgAtomicallyFrame in Closures.h
#define ATOMICALLY_FRAME_FIELDS(w_,p_,info_ptr,p1,p2,code,next,result)  \
    w_ info_ptr,                                                        \
    PROF_HDR_FIELDS(w_,p1,p2)                                           \
    p_ code,                                                            \
    p_ next,                                                            \
    p_ result


INFO_TABLE_RET(stg_partial_atomically_frame, ATOMICALLY_FRAME,
               // layout of the frame, and bind the field names
               ATOMICALLY_FRAME_FIELDS(W_,P_,
                                       info_ptr, p1, p2,
                                       code,
                                       next_invariant,
                                       frame_result))
    return (P_ result) // value returned to the frame
{
    P_ checkpoint;
    gcptr trec, outer, next_invariant, q;

    trec = StgTSO_ptrec(CurrentTSO);

    /* We've got no more invariants to check, try to commit */
    ("ptr" checkpoint) = ccall pa_stmCommitTransaction(MyCapability() "ptr", trec "ptr");

    if(checkpoint == PASTM_SUCCESS){ //Validation succeeded
        frame_result = result;
        return(frame_result);
    }
    if(checkpoint == PASTM_FAIL){ //Validation failed and no checkpoint
	trec = StgTSO_ptrec(CurrentTSO);
		
        ("ptr" trec) = ccall pa_stmStartTransactionAfterAbort(MyCapability() "ptr", trec "ptr");
        StgTSO_ptrec(CurrentTSO) = trec;
        next_invariant = END_INVARIANT_CHECK_QUEUE;

        jump stg_ap_v_fast
            // push the StgAtomicallyFrame again: the code generator is
            // clever enough to only assign the fields that have changed.
            (ATOMICALLY_FRAME_FIELDS(,,info_ptr,p1,p2,
                                     code,next_invariant,frame_result))
            (code);
    }else{//Validation failed, but we have a checkpoint

        P_ k;
        P_ val;

        k = StgPTRecWithK_continuation(checkpoint);
        val = StgPTRecWithK_read_value(checkpoint);

        jump stg_ap_pv_fast  
            // push the StgAtomicallyFrame again: the code generator is
            // clever enough to only assign the fields that have changed.
            (ATOMICALLY_FRAME_FIELDS(,,info_ptr,p1,p2,
                                     code,next_invariant,frame_result))
            (k, val);
    }
}

stg_partial_atomicallyzh (P_ stm)
{
    P_ old_trec;
    P_ new_trec;
    P_ code, next_invariant, frame_result;

    // stmStartTransaction may allocate
    MAYBE_GC_P(stg_partial_atomicallyzh, stm);

    STK_CHK_GEN();

    old_trec = StgTSO_ptrec(CurrentTSO);

    /* Start the memory transcation */
    ("ptr" new_trec) = ccall pa_stmStartTransaction(MyCapability() "ptr", old_trec "ptr");
    StgTSO_ptrec(CurrentTSO) = new_trec;

    code = stm;
    next_invariant = END_INVARIANT_CHECK_QUEUE;
    frame_result = NO_TREC;

    jump stg_ap_v_fast
        (ATOMICALLY_FRAME_FIELDS(,,stg_partial_atomically_frame_info, CCCS, 0,
                                 code,next_invariant,frame_result))
        (stm);
}

stg_partial_atomicallyzhWithEvent(P_ stm, P_ event){
    P_ old_trec;
    P_ new_trec;
    P_ code, next_invariant, frame_result;
    
    MAYBE_GC_PP(stg_partial_atomicallyzhWithEvent, stm, event);

    STK_CHK_GEN();

    old_trec = StgTSO_ptrec(CurrentTSO);

    /* Start the memory transcation */
    ("ptr" new_trec) = ccall pa_stmStartTransactionWithEvent(MyCapability() "ptr", old_trec "ptr", event "ptr");
    StgTSO_ptrec(CurrentTSO) = new_trec;

    code = stm;
    next_invariant = END_INVARIANT_CHECK_QUEUE;
    frame_result = NO_TREC;

    jump stg_ap_v_fast
        (ATOMICALLY_FRAME_FIELDS(,,stg_partial_atomically_frame_info, CCCS, 0,
                                 code,next_invariant,frame_result))
        (stm);
}

stg_partial_eagerFullAbort
{
    W_ frame;
    P_ code; 

    //fully abort -- p_setAtomicallyFrameHelper will unwind the stack to the nearest atomic frame
    //According to StgCmmForeign.hs, SAVE_THREAD_STATE() gets compiled to:
    //tso = CurrentTSO;
    //tso->stackobj->sp = Sp;  --Sp is the register containing the stack pointer
    SAVE_THREAD_STATE();

    //We can use the same C function the partial abort implementation is using
    ccall p_setAtomicallyFrameHelper(MyCapability() "ptr", CurrentTSO "ptr"); 

    /* According to StgCmmForeign.hs:
       tso = CurrentTSO;
       stack = tso->stackobj;
       Sp = stack->sp;
       SpLim = stack->stack + RESERVED_STACK_WORDS;
       HpAlloc = 0;
    //Hopefully PP doesn't stand for pointer pointer, and if it does
    //hopefully it doesn't matter that I am passing in a non-pointer
       --   HpAlloc is assumed to be set to non-zero only by a failed
       --   heap check, see HeapStackCheck.cmm:GC_GENERIC
       p_findAtomicallyFrameHelper will set the tso->stackobj->sp to point to the 
       nearest enclosing atomically frame (there should only be one), so we use
       LOAD_THREAD_STATE() to read the stack pointer out of the TSO and store it in Sp
    */
        
    LOAD_THREAD_STATE();
    frame = Sp;

    //stg_patomically_frame has the same layout as stg_atomically_frame,
    //so just use the macro that they defined for extracting the code
    R1 = StgAtomicallyFrame_code(frame);
    jump stg_ap_v_fast [R1];

}

/*************************************************************************
 * Calling Conventions (comment taken from ghc/compiler/cmm/CmmParse.y)
 * -------------------
 *
 * High-level procedures use the NativeNode calling convention, or the
 * NativeReturn convention if the 'return' keyword is used (see Stack
 * Frames below).
 *
 * Low-level procedures implement their own calling convention, so it can
 * be anything at all.
 *
 * If a low-level procedure implements the NativeNode calling convention,
 * then it can be called by high-level code using an ordinary function
 * call.  In general this is hard to arrange because the calling
 * convention depends on the number of physical registers available for
 * parameter passing, but there are two cases where the calling
 * convention is platform-independent:
 * 
 * - Zero arguments.
 *
 * - One argument of pointer or non-pointer word type; this is always
 *   passed in R1 according to the NativeNode convention.
 * 
 * - Returning a single value; these conventions are fixed and platform
 *   independent.
 *************************************************************************/
//Pass the checkpoint in R1
stg_partial_eagerPartialAbort
{
    P_ k;
    P_ val;

    SAVE_THREAD_STATE(); //see stg_eagerFullAbort for details
    ccall p_setAtomicallyFrameHelper(MyCapability() "ptr", CurrentTSO "ptr");
    LOAD_THREAD_STATE();

    k = StgPTRecWithK_continuation(R1);
    val = StgPTRecWithK_read_value(R1);
    
    jump stg_ap_pv_fast(k, val);

}

stg_partial_readTVarzh (P_ tvar, P_ k)
{
    P_ trec;
    P_ result;
    W_ header;
    
    // Call to stmReadTVar may allocate
    MAYBE_GC_PP (stg_partial_readTVarzh, tvar, k);

    trec = StgTSO_ptrec(CurrentTSO);
    ("ptr" result) = ccall pa_stmReadTVar(MyCapability() "ptr", trec "ptr",
					  tvar "ptr", k "ptr");
    
    if(result == PASTM_FAIL){
        jump stg_partial_eagerFullAbort []; //full abort
    }
    
    header = StgHeader_info(result);

    if(header == stg_PTREC_WITHK_info){
        jump stg_partial_eagerPartialAbort(result);
    }

    return (result);
}



stg_partial_writeTVarzh (P_ tvar,     /* :: TVar a */
		      P_ new_value /* :: a      */)
{
    W_ trec;

    // Call to stmWriteTVar may allocate
    MAYBE_GC_PP (stg_partial_writeTVarzh, tvar, new_value);

    trec = StgTSO_ptrec(CurrentTSO);
    ccall pa_stmWriteTVar(MyCapability() "ptr", trec "ptr", tvar "ptr",
						  new_value "ptr");
    return (tvar);
}


/*
 * Bail on a transaction, execution should continue with the alternative
 * branch of the nearest orElse.  We currently are not supporting the 
 * blocking semantics of retry if it propogates all the way up to the 
 * top of the transaction.  Instead, we simply immediatly retry.
 */
stg_partial_retryzh()
{

    W_ trec;
    W_ alt;
    W_ retry_stack;
     
    trec = StgTSO_ptrec(CurrentTSO);

    retry_stack = StgPTRecHeader_retry_stack(trec);
    
    if(retry_stack == NO_PTREC){
        jump stg_eagerFullAbort []; //retry from beginning
    }

    //Have at least one catchRetry on our retry_stack
    ("ptr" alt) = ccall pa_stmRetry(trec "ptr");
    
    jump stg_ap_v_fast(alt);
}

stg_partial_popRetry(P_ x)
{
    W_ trec;
    W_ retry_stack;
 
    trec = StgTSO_ptrec(CurrentTSO);

    retry_stack = StgPTRecHeader_retry_stack(trec);
    StgPTRecHeader_retry_stack(trec) = StgPTRecOrElse_next(retry_stack);

    return(x);
}

stg_partial_catchRetryzh (P_ first_code,     /* :: STM a */
			  P_ alt_code       /* :: STM a */)
{

    W_ trec;
    W_ retry_stack;

    MAYBE_GC_PP(stg_pcatchRetryzh, first_code, alt_code);

    trec = StgTSO_ptrec(CurrentTSO);
    ccall pa_stmCatchRetry(MyCapability() "ptr", trec "ptr", 
			   alt_code "ptr");
    
    jump stg_ap_v_fast (first_code);
}




